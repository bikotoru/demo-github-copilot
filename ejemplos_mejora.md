# üöÄ Ejemplos de Mejoras para AI Document Reader

Esta lista contiene prompts espec√≠ficos y claros para implementar mejoras en la aplicaci√≥n. Cada mejora est√° dise√±ada para ser implementada de forma independiente y probar las capacidades de IA para desarrollo.

## üìã Formato de Prompts

Cada prompt sigue esta estructura para mejores resultados:

```
#file:[nombre del archivo]
En [lenguaje de programaci√≥n], usando [framework], crea [descripci√≥n de la tarea]:
- Objetivo principal: [qu√© se quiere lograr]
- Requisitos espec√≠ficos: [lista detallada de caracter√≠sticas]
- Contexto: [situaci√≥n actual y por qu√© se necesita]
- Restricciones: [limitaciones t√©cnicas y de dise√±o]
```

## üéØ Mejoras Prioritarias

Las siguientes 3 mejoras est√°n listas para implementar con prompts estructurados:

---

# Mejora 1: Historial de Conversaciones Persistente

**Prompt Estructurado:**

```
#file:backend/main.py
#file:frontend/components/chat.tsx
#file:frontend/app/page.tsx

En Python usando FastAPI y TypeScript usando Next.js con React, implementa desde cero un sistema de historial de conversaciones persistente:

- Objetivo principal: Crear un sistema completo para guardar y navegar conversaciones entre el usuario y la IA
- Requisitos espec√≠ficos:
  * Backend: Crear endpoints GET /conversations, GET /conversations/{id}, POST /conversations, DELETE /conversations/{id}, PUT /conversations/{id}
  * ESTRUCTURA CORRECTA del JSON: Una conversaci√≥n = UN objeto con m√∫ltiples mensajes dentro
  * Estructura conversations.json:
    ```json
    [
      {
        "id": "uuid-unico",
        "title": "T√≠tulo auto-generado",
        "created_at": "2025-01-01T12:00:00Z",
        "updated_at": "2025-01-01T12:05:00Z",
        "messages": [
          {"user": "Hola", "timestamp": "2025-01-01T12:00:00Z"},
          {"assistant": "¬°Hola! ¬øC√≥mo puedo ayudarte?", "timestamp": "2025-01-01T12:00:30Z"},
          {"user": "¬øQu√© es Python?", "timestamp": "2025-01-01T12:01:00Z"},
          {"assistant": "Python es un lenguaje...", "timestamp": "2025-01-01T12:01:30Z"}
        ]
      }
    ]
    ```
  * FLUJO CORRECTO: 
    1. Al enviar primer mensaje ‚Üí crear nueva conversaci√≥n con POST /conversations
    2. Al enviar mensajes siguientes ‚Üí actualizar conversaci√≥n existente con PUT /conversations/{id}
    3. Una conversaci√≥n puede tener N mensajes, NO crear nueva conversaci√≥n por cada mensaje
  * Frontend: Modificar el componente Chat para agregar sidebar elegante con lista de conversaciones
  * NAVEGACI√ìN POR URL: Implementar ?id=xxx en la URL para navegar directamente a conversaciones espec√≠ficas
    - URL: http://localhost:3000/?id=uuid-conversacion
    - Al cargar la p√°gina, detectar par√°metro ?id y cargar esa conversaci√≥n autom√°ticamente
    - Al seleccionar conversaci√≥n del sidebar, actualizar URL con ?id=xxx sin recargar p√°gina
    - Bot√≥n "Nueva conversaci√≥n" debe limpiar el par√°metro ?id de la URL
  * Implementar funcionalidad completa: crear, cargar, eliminar conversaciones
  * Auto-generar t√≠tulos basados en los primeros 50 caracteres del primer mensaje del usuario
  * Usar componentes ShadCN UI existentes (Button, ScrollArea, Separator, etc.) con dise√±o moderno y elegante
  * Aplicar hover effects, transiciones suaves y micro-interacciones para una experiencia premium
  * El sidebar debe verse profesional con iconos apropiados, espaciado correcto y jerarqu√≠a visual clara
- Contexto: La aplicaci√≥n actual es un chat b√°sico en frontend/components/chat.tsx que se conecta al backend FastAPI con streaming. Necesitamos agregar persistencia y navegaci√≥n por URL.
- Restricciones: 
  * No usar base de datos, solo archivos JSON
  * Mantener compatibilidad con el sistema de streaming actual en /chat/stream
  * CR√çTICO: Una conversaci√≥n = un objeto JSON con array de mensajes
  * Implementar navegaci√≥n por URL con par√°metros de query (?id=xxx)
  * PERSISTENCIA DE ESTADO: Al cambiar la URL/ruta, mantener la conexi√≥n activa con la conversaci√≥n sin perder datos
  * CONFIRMACI√ìN DE ELIMINACI√ìN: Al eliminar conversaci√≥n, mostrar dialog/alert de confirmaci√≥n antes de proceder
  * ACTUALIZACI√ìN DIN√ÅMICA: Al eliminar conversaci√≥n, remover inmediatamente del sidebar sin recargar p√°gina
  * DISE√ëO RESPONSIVO COMPLETO: La aplicaci√≥n debe funcionar perfectamente en m√≥viles, tablets y desktop
    - Sidebar colapsable en m√≥viles con animaciones fluidas usando componentes ShadCN UI
    - Chat area debe adaptarse correctamente a diferentes tama√±os de pantalla
    - Input y botones deben ser touch-friendly en m√≥viles
    - Textos y elementos UI deben escalar apropiadamente
  * Mantener el theme provider y modo oscuro existente con transiciones elegantes entre temas
  * M√°ximo 100 conversaciones guardadas (eliminar las m√°s antiguas autom√°ticamente)
  * Dise√±o general debe ser visualmente atractivo, moderno y profesional, similar a aplicaciones como ChatGPT o Claude
```

**Archivos a crear/modificar:**
- `backend/main.py` (agregar endpoints de conversaciones)
- `frontend/components/chat.tsx` (agregar sidebar y l√≥gica de navegaci√≥n URL)
- `backend/conversations.json` (archivo de almacenamiento)

---

# Mejora 2: Soporte para Renderizado de Markdown

**Prompt Estructurado:**

```
#file:frontend/components/chat.tsx

En TypeScript usando Next.js con React y ShadCN UI, agrega soporte para renderizado de Markdown en los mensajes del chat:

- Objetivo principal: Los mensajes de la IA deben mostrarse con formato Markdown (c√≥digo, listas, enlaces, etc.) en lugar de texto plano
- Requisitos espec√≠ficos:
  * Solo los mensajes de la IA deben renderizarse como Markdown (los mensajes del usuario siguen como texto plano)
  * Soporte para: bloques de c√≥digo con syntax highlighting, c√≥digo inline, listas, enlaces, tablas, citas, im√°genes
  * Bot√≥n "copiar" en bloques de c√≥digo con feedback visual
  * Dise√±o elegante que mantenga la consistencia visual del chat actual
  * Totalmente responsivo - no debe romper el dise√±o en m√≥viles
  * Integraci√≥n perfecta con tema oscuro/claro existente
  * Sanitizaci√≥n de contenido por seguridad
  * Compatible con streaming incremental (renderizar mientras se recibe el texto)
- Contexto: Chat con IA que actualmente muestra todos los mensajes como texto plano, pero la IA responde con Markdown
- Restricciones:
  * SOLO modificar el frontend - NO tocar backend/main.py ni endpoints
  * No afectar el streaming ni la funcionalidad existente del chat
  * Mantener el dise√±o responsivo actual
  * Usar componentes ShadCN UI existentes donde sea posible
```

**Archivos a modificar:**
- `frontend/components/chat.tsx` (agregar renderizado Markdown solo para mensajes IA)

---

# Mejora 3: Contador de Tokens de Entrada y Salida

**Prompt Estructurado:**

```
#file:backend/main.py
#file:frontend/components/chat.tsx

En Python usando FastAPI y TypeScript usando Next.js con ShadCN UI, implementa un sistema de conteo de tokens:

- Objetivo principal: Mostrar tokens de entrada y salida consumidos en cada mensaje para control de costos
- Requisitos espec√≠ficos:
  * Backend: Modificar el endpoint /chat/stream para calcular tokens antes y despu√©s de cada llamada a Gemini
  * Usar la funci√≥n count_tokens() de la API de Gemini para conteo preciso
  * Retornar en la respuesta streaming: input_tokens, output_tokens, total_tokens
  * Frontend: Modificar el componente Chat existente para mostrar contadores elegantes debajo de cada mensaje con iconos de Lucide React
  * Agregar contador total de la sesi√≥n visualmente atractivo en la cabecera del chat (junto al toggle de tema)
  * Mostrar costo estimado basado en precios actuales de Gemini (input: $0.000125/1K tokens, output: $0.000375/1K tokens) con formato monetario claro
  * Usar Badge component de ShadCN UI con colores apropiados y dise√±o pulido para mostrar la informaci√≥n de tokens
  * Implementar micro-animaciones y transiciones suaves para la actualizaci√≥n de contadores
  * Dise√±o de contadores debe ser discreto pero informativo, con jerarqu√≠a visual clara y est√©tica profesional
- Contexto: La aplicaci√≥n actual usa streaming en /chat/stream y el componente Chat, los usuarios necesitan controlar costos
- Restricciones:
  * Mantener compatibilidad con streaming actual (actualizar contadores en tiempo real durante el stream)
  * Los contadores deben ser discretos visualmente usando componentes ShadCN UI pero informativos
  * Incluir Toggle component elegante para ocultar/mostrar informaci√≥n de tokens con transiciones suaves
  * Calcular tokens solo cuando sea necesario para optimizar rendimiento
  * Respetar el tema oscuro/claro existente con dise√±o cohesivo y profesional
  * La interfaz completa debe mantener la elegancia y modernidad del chat existente
```

**Archivos a modificar:**
- `backend/main.py` (c√°lculo de tokens)
- `frontend/components/chat.tsx` (UI de contadores)

---

## üí° Instrucciones de Uso

1. **Copia el prompt estructurado** de cualquiera de las 3 mejoras anteriores
2. **P√©galo directamente** en tu modelo de IA preferido (Claude, ChatGPT, etc.)
3. **El modelo tendr√° contexto completo** sobre los archivos existentes y qu√© hacer
4. **Cada mejora es independiente** - puede implementarse sin las otras
5. **Formato probado** - esta estructura da mejores resultados que prompts simples

## üîÑ Pr√≥ximas Mejoras

Si estas 3 mejoras funcionan bien, podemos crear m√°s prompts estructurados para:
- Subida y an√°lisis de documentos
- Sistema de plantillas de prompts  
- An√°lisis de im√°genes con Gemini Vision
- Exportaci√≥n de conversaciones
- Dashboard de estad√≠sticas
- B√∫squeda global en conversaciones

---

# Mejora 4: Migraci√≥n del Backend a .NET 9

**Prompt Estructurado:**

```
#file:backend/main.py

En C# usando .NET 9 con ASP.NET Core Minimal APIs, migra completamente el backend actual de Python FastAPI a .NET:

- Objetivo principal: Reemplazar el backend Python por una implementaci√≥n equivalente en .NET 9 manteniendo toda la funcionalidad
- Requisitos espec√≠ficos:
  * Crear nuevo proyecto .NET 9 con Minimal APIs (Program.cs)
  * Implementar todos los endpoints existentes: GET /, GET /health, GET /test-gemini, POST /chat, POST /chat/stream
  * Integrar Google Gemini API usando HttpClient y JSON para las llamadas REST
  * Configurar CORS para permitir conexiones desde localhost:3000
  * Implementar streaming de respuestas usando Server-Sent Events (SSE)
  * Usar System.Text.Json para serializaci√≥n/deserializaci√≥n
  * Configurar variables de entorno con appsettings.json y User Secrets
  * Mantener la misma estructura de request/response que el Python actual
- Contexto: El backend Python funciona perfectamente, pero necesitamos una versi√≥n .NET para comparar rendimiento y explorar el ecosistema .NET
- Restricciones:
  * Mantener exactamente la misma API (mismos endpoints, mismos formatos JSON)
  * El frontend Next.js NO debe necesitar cambios
  * Usar solo librer√≠as nativas de .NET, no paquetes third-party para Gemini
  * Configurar puerto 8001 para evitar conflictos con el Python (puerto 8000)
  * Incluir logging con ILogger para debugging
  * Manejar errores de forma robusta con try-catch
```

**Archivos a crear:**
- `backend-dotnet/Program.cs` (API principal)
- `backend-dotnet/Models/ChatModels.cs` (DTOs)
- `backend-dotnet/Services/GeminiService.cs` (integraci√≥n con Gemini)
- `backend-dotnet/backend-dotnet.csproj` (proyecto)
- `backend-dotnet/appsettings.json` (configuraci√≥n)
- `backend-dotnet/README.md` (instrucciones espec√≠ficas .NET)

**Estructura esperada:**
```
backend-dotnet/
‚îú‚îÄ‚îÄ Program.cs
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îî‚îÄ‚îÄ ChatModels.cs
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îî‚îÄ‚îÄ GeminiService.cs
‚îú‚îÄ‚îÄ backend-dotnet.csproj
‚îú‚îÄ‚îÄ appsettings.json
‚îî‚îÄ‚îÄ README.md
```

---

