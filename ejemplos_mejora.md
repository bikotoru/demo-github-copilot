# üöÄ Ejemplos de Mejoras para AI Document Reader

Esta lista contiene prompts espec√≠ficos y claros para implementar mejoras en la aplicaci√≥n. Cada mejora est√° dise√±ada para ser implementada de forma independiente y probar las capacidades de IA para desarrollo.

## üìã Formato de Prompts

Cada prompt sigue esta estructura para mejores resultados:

```
#file:[nombre del archivo]
En [lenguaje de programaci√≥n], usando [framework], crea [descripci√≥n de la tarea]:
- Objetivo principal: [qu√© se quiere lograr]
- Requisitos espec√≠ficos: [lista detallada de caracter√≠sticas]
- Contexto: [situaci√≥n actual y por qu√© se necesita]
- Restricciones: [limitaciones t√©cnicas y de dise√±o]
```

## üéØ Mejoras Prioritarias

Las siguientes 3 mejoras est√°n listas para implementar con prompts estructurados:

---

# Mejora 1: Historial de Conversaciones Persistente

**Prompt Estructurado:**

```
#file:backend/main.py
#file:templatenextjs/app/ai-chat/page.tsx

En Python usando FastAPI y TypeScript usando Next.js con React, crea un sistema de historial de conversaciones persistente:

- Objetivo principal: Guardar y recuperar conversaciones completas entre el usuario y la IA
- Requisitos espec√≠ficos:
  * Backend: Crear endpoints GET /conversations, GET /conversations/{id}, POST /conversations, DELETE /conversations/{id}
  * Cada conversaci√≥n debe tener: id √∫nico (UUID), t√≠tulo auto-generado, timestamp de creaci√≥n, array de mensajes
  * Almacenar datos en archivo JSON (conversations.json) sin base de datos
  * Frontend: Agregar sidebar izquierdo con lista de conversaciones, click para cargar conversaci√≥n
  * Auto-generar t√≠tulos basados en los primeros 50 caracteres del primer mensaje del usuario
- Contexto: La aplicaci√≥n actual es un chat con IA que usa streaming, pero las conversaciones se pierden al recargar
- Restricciones: 
  * No usar base de datos, solo archivos JSON
  * Mantener compatibilidad con el sistema de streaming actual
  * El sidebar debe ser responsive y colapsable en m√≥viles
  * M√°ximo 100 conversaciones guardadas (eliminar las m√°s antiguas autom√°ticamente)
```

**Archivos a modificar:**
- `backend/main.py` (nuevos endpoints)
- `templatenextjs/app/ai-chat/page.tsx` (sidebar y funcionalidad)
- Crear: `backend/conversations.json` (almacenamiento)

---

# Mejora 2: Soporte para Renderizado de Markdown

**Prompt Estructurado:**

```
#file:templatenextjs/app/ai-chat/page.tsx

En TypeScript usando Next.js con React y ShadCN UI, implementa renderizado de Markdown en los mensajes del chat:

- Objetivo principal: Mostrar mensajes con formato Markdown (negrita, cursiva, c√≥digo, listas, enlaces, etc.)
- Requisitos espec√≠ficos:
  * Instalar y configurar react-markdown y react-syntax-highlighter
  * Renderizar mensajes de la IA con formato Markdown completo
  * Syntax highlighting para bloques de c√≥digo con nombres de lenguajes
  * Soporte para tablas, listas, enlaces, im√°genes
  * Mantener el estilo visual actual del chat (colores, espaciado, bordes redondeados)
  * Agregar bot√≥n "copiar c√≥digo" en bloques de c√≥digo
- Contexto: Los mensajes actualmente se muestran como texto plano, pero la IA a menudo responde con Markdown
- Restricciones:
  * Mantener compatibilidad con el streaming actual (renderizar Markdown incremental)
  * Los estilos deben respetar el tema oscuro/claro actual
  * Sanitizar contenido para evitar XSS
  * No afectar el rendimiento del streaming
```

**Archivos a modificar:**
- `templatenextjs/app/ai-chat/page.tsx` (renderizado de markdown)
- `templatenextjs/package.json` (nuevas dependencias)

---

# Mejora 3: Contador de Tokens de Entrada y Salida

**Prompt Estructurado:**

```
#file:backend/main.py
#file:templatenextjs/app/ai-chat/page.tsx

En Python usando FastAPI y TypeScript usando Next.js, implementa un sistema de conteo de tokens:

- Objetivo principal: Mostrar tokens de entrada y salida consumidos en cada mensaje para control de costos
- Requisitos espec√≠ficos:
  * Backend: Calcular tokens antes y despu√©s de cada llamada a Gemini
  * Usar la funci√≥n count_tokens() de la API de Gemini para conteo preciso
  * Retornar en la respuesta: input_tokens, output_tokens, total_tokens
  * Frontend: Mostrar contadores debajo de cada mensaje con iconos
  * Agregar contador total de la sesi√≥n en la parte superior del chat
  * Mostrar costo estimado basado en precios actuales de Gemini
- Contexto: Los usuarios necesitan controlar el consumo de tokens para gestionar costos de API
- Restricciones:
  * Mantener compatibilidad con streaming (actualizar contadores en tiempo real)
  * Los contadores deben ser discretos visualmente pero informativos
  * Incluir opci√≥n para ocultar/mostrar informaci√≥n de tokens
  * Calcular tokens solo cuando sea necesario para optimizar rendimiento
```

**Archivos a modificar:**
- `backend/main.py` (c√°lculo de tokens)
- `templatenextjs/app/ai-chat/page.tsx` (UI de contadores)

---

## üí° Instrucciones de Uso

1. **Copia el prompt estructurado** de cualquiera de las 3 mejoras anteriores
2. **P√©galo directamente** en tu modelo de IA preferido (Claude, ChatGPT, etc.)
3. **El modelo tendr√° contexto completo** sobre los archivos existentes y qu√© hacer
4. **Cada mejora es independiente** - puede implementarse sin las otras
5. **Formato probado** - esta estructura da mejores resultados que prompts simples

## üîÑ Pr√≥ximas Mejoras

Si estas 3 mejoras funcionan bien, podemos crear m√°s prompts estructurados para:
- Subida y an√°lisis de documentos
- Sistema de plantillas de prompts  
- An√°lisis de im√°genes con Gemini Vision
- Exportaci√≥n de conversaciones
- Dashboard de estad√≠sticas
- B√∫squeda global en conversaciones

---

# Mejora 4: Migraci√≥n del Backend a .NET 9

**Prompt Estructurado:**

```
#file:backend/main.py

En C# usando .NET 9 con ASP.NET Core Minimal APIs, migra completamente el backend actual de Python FastAPI a .NET:

- Objetivo principal: Reemplazar el backend Python por una implementaci√≥n equivalente en .NET 9 manteniendo toda la funcionalidad
- Requisitos espec√≠ficos:
  * Crear nuevo proyecto .NET 9 con Minimal APIs (Program.cs)
  * Implementar todos los endpoints existentes: GET /, GET /health, GET /test-gemini, POST /chat, POST /chat/stream
  * Integrar Google Gemini API usando HttpClient y JSON para las llamadas REST
  * Configurar CORS para permitir conexiones desde localhost:3000
  * Implementar streaming de respuestas usando Server-Sent Events (SSE)
  * Usar System.Text.Json para serializaci√≥n/deserializaci√≥n
  * Configurar variables de entorno con appsettings.json y User Secrets
  * Mantener la misma estructura de request/response que el Python actual
- Contexto: El backend Python funciona perfectamente, pero necesitamos una versi√≥n .NET para comparar rendimiento y explorar el ecosistema .NET
- Restricciones:
  * Mantener exactamente la misma API (mismos endpoints, mismos formatos JSON)
  * El frontend Next.js NO debe necesitar cambios
  * Usar solo librer√≠as nativas de .NET, no paquetes third-party para Gemini
  * Configurar puerto 8001 para evitar conflictos con el Python (puerto 8000)
  * Incluir logging con ILogger para debugging
  * Manejar errores de forma robusta con try-catch
```

**Archivos a crear:**
- `backend-dotnet/Program.cs` (API principal)
- `backend-dotnet/Models/ChatModels.cs` (DTOs)
- `backend-dotnet/Services/GeminiService.cs` (integraci√≥n con Gemini)
- `backend-dotnet/backend-dotnet.csproj` (proyecto)
- `backend-dotnet/appsettings.json` (configuraci√≥n)
- `backend-dotnet/README.md` (instrucciones espec√≠ficas .NET)

**Estructura esperada:**
```
backend-dotnet/
‚îú‚îÄ‚îÄ Program.cs
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îî‚îÄ‚îÄ ChatModels.cs
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îî‚îÄ‚îÄ GeminiService.cs
‚îú‚îÄ‚îÄ backend-dotnet.csproj
‚îú‚îÄ‚îÄ appsettings.json
‚îî‚îÄ‚îÄ README.md
```

---

**¬øListo para probar? Copia cualquier prompt y pru√©balo con tu IA favorita! üöÄ**